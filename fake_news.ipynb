{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import  classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(' ', inplace=True)\n",
    "test_df.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['author'] + ' ' + train_df['title'] + ' ' + train_df['text']\n",
    "test_df['text'] = test_df['author'] + ' ' + test_df['title'] + ' ' + test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/grigorii/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "porter_stemmer = PorterStemmer()  \n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower().split()\n",
    "    text = [porter_stemmer.stem(word) for word in text if word not in stopwords.words('english')]\n",
    "    return text\n",
    "\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(preprocess_text)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"label\"].values\n",
    "train_normalized = train_df[\"text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train_normalized, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "def text_to_vector(text, model, vector_size=100):\n",
    "    vectors = [model.wv[word] for word in text if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "ready_X = np.array([text_to_vector(text, word2vec_model) for text in train_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17005411, -0.06975884, -0.97706306, ...,  0.41913012,\n",
       "        -0.76474208,  0.29716259],\n",
       "       [-0.01866901, -0.18739831, -0.96270233, ...,  0.21786672,\n",
       "        -0.65085131,  0.73862445],\n",
       "       [ 0.12808317, -0.48967269, -0.79332817, ..., -0.20019738,\n",
       "        -0.3065162 ,  1.13307989],\n",
       "       ...,\n",
       "       [-0.13699907, -0.38939902, -0.62628883, ..., -0.05546546,\n",
       "        -0.40605801,  0.70770413],\n",
       "       [ 0.09616299, -0.74483943, -0.53934503, ...,  0.22275048,\n",
       "         0.21181351,  0.72581404],\n",
       "       [-0.0765762 , -0.17861092, -0.50527352, ..., -0.23413526,\n",
       "        -0.33993483,  0.88086396]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2074\n",
      "           1       0.92      0.91      0.92      2086\n",
      "\n",
      "    accuracy                           0.92      4160\n",
      "   macro avg       0.92      0.92      0.92      4160\n",
      "weighted avg       0.92      0.92      0.92      4160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(ready_X, y, test_size=0.2)\n",
    "\n",
    "model_1 = LogisticRegression()\n",
    "model_1.fit(x_train, y_train)\n",
    "pred_1 = model_1.predict(x_test)\n",
    "print(classification_report(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      2060\n",
      "           1       0.90      0.87      0.89      2100\n",
      "\n",
      "    accuracy                           0.89      4160\n",
      "   macro avg       0.89      0.89      0.89      4160\n",
      "weighted avg       0.89      0.89      0.89      4160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(ready_X, y, test_size=0.2)\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred = gb_clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53      2074\n",
      "           1       0.53      0.51      0.52      2086\n",
      "\n",
      "    accuracy                           0.53      4160\n",
      "   macro avg       0.53      0.53      0.53      4160\n",
      "weighted avg       0.53      0.53      0.53      4160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(x_train,y_train)\n",
    "pred_3 = model_3.predict(x_test)\n",
    "cr3    = classification_report(y_test,pred_3)\n",
    "print(cr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate=0):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x.unsqueeze(1))\n",
    "        x = self.fc(lstm_out[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(X_train, y_train)\n",
    "val_dataset = NewsDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(input_size=100, hidden_size=100, num_layers=2, output_size=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 238.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "LSTM Neural Network Accuracy: 0.8903846153846153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      2079\n",
      "           1       0.86      0.94      0.90      2081\n",
      "\n",
      "    accuracy                           0.89      4160\n",
      "   macro avg       0.89      0.89      0.89      4160\n",
      "weighted avg       0.89      0.89      0.89      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:03<00:00, 302.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "LSTM Neural Network Accuracy: 0.901201923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      2079\n",
      "           1       0.88      0.93      0.90      2081\n",
      "\n",
      "    accuracy                           0.90      4160\n",
      "   macro avg       0.90      0.90      0.90      4160\n",
      "weighted avg       0.90      0.90      0.90      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:03<00:00, 286.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "LSTM Neural Network Accuracy: 0.9161057692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2079\n",
      "           1       0.92      0.92      0.92      2081\n",
      "\n",
      "    accuracy                           0.92      4160\n",
      "   macro avg       0.92      0.92      0.92      4160\n",
      "weighted avg       0.92      0.92      0.92      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:03<00:00, 335.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "LSTM Neural Network Accuracy: 0.9170673076923077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      2079\n",
      "           1       0.95      0.89      0.91      2081\n",
      "\n",
      "    accuracy                           0.92      4160\n",
      "   macro avg       0.92      0.92      0.92      4160\n",
      "weighted avg       0.92      0.92      0.92      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:03<00:00, 262.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "LSTM Neural Network Accuracy: 0.9132211538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      2079\n",
      "           1       0.88      0.95      0.92      2081\n",
      "\n",
      "    accuracy                           0.91      4160\n",
      "   macro avg       0.92      0.91      0.91      4160\n",
      "weighted avg       0.92      0.91      0.91      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 254.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "LSTM Neural Network Accuracy: 0.9264423076923077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      2079\n",
      "           1       0.93      0.92      0.93      2081\n",
      "\n",
      "    accuracy                           0.93      4160\n",
      "   macro avg       0.93      0.93      0.93      4160\n",
      "weighted avg       0.93      0.93      0.93      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 240.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "LSTM Neural Network Accuracy: 0.9235576923076924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      2079\n",
      "           1       0.93      0.92      0.92      2081\n",
      "\n",
      "    accuracy                           0.92      4160\n",
      "   macro avg       0.92      0.92      0.92      4160\n",
      "weighted avg       0.92      0.92      0.92      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 236.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "LSTM Neural Network Accuracy: 0.9225961538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      2079\n",
      "           1       0.96      0.88      0.92      2081\n",
      "\n",
      "    accuracy                           0.92      4160\n",
      "   macro avg       0.93      0.92      0.92      4160\n",
      "weighted avg       0.93      0.92      0.92      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 239.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "LSTM Neural Network Accuracy: 0.9283653846153846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2079\n",
      "           1       0.94      0.92      0.93      2081\n",
      "\n",
      "    accuracy                           0.93      4160\n",
      "   macro avg       0.93      0.93      0.93      4160\n",
      "weighted avg       0.93      0.93      0.93      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 230.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "LSTM Neural Network Accuracy: 0.9319711538461538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      2079\n",
      "           1       0.93      0.94      0.93      2081\n",
      "\n",
      "    accuracy                           0.93      4160\n",
      "   macro avg       0.93      0.93      0.93      4160\n",
      "weighted avg       0.93      0.93      0.93      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 229.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "LSTM Neural Network Accuracy: 0.9199519230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      2079\n",
      "           1       0.95      0.88      0.92      2081\n",
      "\n",
      "    accuracy                           0.92      4160\n",
      "   macro avg       0.92      0.92      0.92      4160\n",
      "weighted avg       0.92      0.92      0.92      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 236.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "LSTM Neural Network Accuracy: 0.9293269230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2079\n",
      "           1       0.94      0.92      0.93      2081\n",
      "\n",
      "    accuracy                           0.93      4160\n",
      "   macro avg       0.93      0.93      0.93      4160\n",
      "weighted avg       0.93      0.93      0.93      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 231.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "LSTM Neural Network Accuracy: 0.9317307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      2079\n",
      "           1       0.95      0.91      0.93      2081\n",
      "\n",
      "    accuracy                           0.93      4160\n",
      "   macro avg       0.93      0.93      0.93      4160\n",
      "weighted avg       0.93      0.93      0.93      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:03<00:00, 335.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "LSTM Neural Network Accuracy: 0.9317307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      2079\n",
      "           1       0.95      0.92      0.93      2081\n",
      "\n",
      "    accuracy                           0.93      4160\n",
      "   macro avg       0.93      0.93      0.93      4160\n",
      "weighted avg       0.93      0.93      0.93      4160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:04<00:00, 233.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "LSTM Neural Network Accuracy: 0.9310096153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      2079\n",
      "           1       0.92      0.95      0.93      2081\n",
      "\n",
      "    accuracy                           0.93      4160\n",
      "   macro avg       0.93      0.93      0.93      4160\n",
      "weighted avg       0.93      0.93      0.93      4160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in tqdm(train_loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    y_preds, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_preds.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(y_batch.numpy())\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(classification_report(y_true, y_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andan_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
